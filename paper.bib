@article{jackson_using_2021,
	title = {Using prototyping to choose a bioinformatics workflow management system},
	volume = {17},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008622},
	doi = {10.1371/journal.pcbi.1008622},
	abstract = {Workflow management systems represent, manage, and execute multistep computational analyses and offer many benefits to bioinformaticians. They provide a common language for describing analysis workflows, contributing to reproducibility and to building libraries of reusable components. They can support both incremental build and re-entrancy—the ability to selectively re-execute parts of a workflow in the presence of additional inputs or changes in configuration and to resume execution from where a workflow previously stopped. Many workflow management systems enhance portability by supporting the use of containers, high-performance computing (HPC) systems, and clouds. Most importantly, workflow management systems allow bioinformaticians to delegate how their workflows are run to the workflow management system and its developers. This frees the bioinformaticians to focus on what these workflows should do, on their data analyses, and on their science. RiboViz is a package to extract biological insight from ribosome profiling data to help advance understanding of protein synthesis. At the heart of RiboViz is an analysis workflow, implemented in a Python script. To conform to best practices for scientific computing which recommend the use of build tools to automate workflows and to reuse code instead of rewriting it, the authors reimplemented this workflow within a workflow management system. To select a workflow management system, a rapid survey of available systems was undertaken, and candidates were shortlisted: Snakemake, cwltool, Toil, and Nextflow. Each candidate was evaluated by quickly prototyping a subset of the RiboViz workflow, and Nextflow was chosen. The selection process took 10 person-days, a small cost for the assurance that Nextflow satisfied the authors’ requirements. The use of prototyping can offer a low-cost way of making a more informed selection of software to use within projects, rather than relying solely upon reviews and recommendations by others.},
	language = {en},
	number = {2},
	urldate = {2025-10-31},
	journal = {PLOS Computational Biology},
	author = {Jackson, Michael and Kavoussanakis, Kostas and Wallace, Edward W. J.},
	month = feb,
	year = {2021},
	note = {Publisher: Public Library of Science},
	keywords = {Computer software, Sequence alignment, Bioinformatics, Ribosomal RNA, Language, Pythons, Open source software, Prototypes},
	pages = {e1008622},
}

@article{celebi_creating_2023,
	title = {Creating reproducible workflows for complex computational pipelines},
	issn = {2998-4084},
	url = {https://research.arcadiascience.com/pub/perspective-reproducible-workflows/release/5/},
	doi = {10.57844/arcadia-cc5j-a519},
	abstract = {A workflow orchestration framework can streamline repeatable tasks and make workflows broadly usable. From several options, we chose Nextflow due to the ease of deploying across platforms, vibrant nf-core community, and ability to manage and monitor workflows with Nextflow Tower.},
	language = {en},
	urldate = {2025-10-31},
	author = {Celebi, Feridun Mert and Chou, Seemay and Gehring, Jase and Hochstrasser, Megan L. and McDaniel, Elizabeth A. and Patton, Austin H. and Reiter, Taylor and Sun, Dennis A.},
	month = feb,
	year = {2023},
	note = {Publisher: Arcadia Science},
	file = {Snapshot:C\:\\Users\\USER\\Zotero\\storage\\YGDGWUIE\\5.html:text/html},
}

@misc{stamouli_nf-coretaxprofiler_2023,
	title = {nf-core/taxprofiler: highly parallelised and flexible pipeline for metagenomic taxonomic classification and profiling},
	copyright = {© 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	shorttitle = {nf-core/taxprofiler},
	url = {https://www.biorxiv.org/content/10.1101/2023.10.20.563221v1},
	doi = {10.1101/2023.10.20.563221},
	abstract = {1 Abstract
Metagenomic classification tackles the problem of characterising the taxonomic source of all DNA sequencing reads in a sample. A common approach to address the differences and biases between the many different taxonomic classification tools is to run metagenomic data through multiple classification tools and databases. This, however, is a very time-consuming task when performed manually - particularly when combined with the appropriate preprocessing of sequencing reads before the classification.
Here we present nf-core/taxprofiler, a highly parallelised read-processing and taxonomic classification pipeline. It is designed for the automated and simultaneous classification and/or profiling of both short- and long-read metagenomic sequencing libraries against a 11 taxonomic classifiers and profilers as well as databases within a single pipeline run. Implemented in Nextflow and as part of the nf-core initiative, the pipeline benefits from high levels of scalability and portability, accommodating from small to extremely large projects on a wide range of computing infrastructure. It has been developed following best-practise software development practises and community support to ensure longevity and adaptability of the pipeline, to help keep it up to date with the field of metagenomics.},
	language = {en},
	urldate = {2025-10-31},
	publisher = {bioRxiv},
	author = {Stamouli, Sofia and Beber, Moritz E. and Normark, Tanja and Christensen, Thomas A. and Andersson-Li, Lili and Borry, Maxime and Jamy, Mahwash and Community, Nf-Core and Yates, James A. Fellows},
	month = oct,
	year = {2023},
	note = {Pages: 2023.10.20.563221
Section: New Results},
}

@article{petit_bactopia_2020,
	title = {Bactopia: a {Flexible} {Pipeline} for {Complete} {Analysis} of {Bacterial} {Genomes}},
	volume = {5},
	shorttitle = {Bactopia},
	url = {https://journals.asm.org/doi/10.1128/msystems.00190-20},
	doi = {10.1128/msystems.00190-20},
	abstract = {Sequencing of bacterial genomes using Illumina technology has become such a standard procedure that often data are generated faster than can be conveniently analyzed. We created a new series of pipelines called Bactopia, built using Nextflow workflow software, to provide efficient comparative genomic analyses for bacterial species or genera. Bactopia consists of a data set setup step (Bactopia Data Sets [BaDs]), which creates a series of customizable data sets for the species of interest, the Bactopia Analysis Pipeline (BaAP), which performs quality control, genome assembly, and several other functions based on the available data sets and outputs the processed data to a structured directory format, and a series of Bactopia Tools (BaTs) that perform specific postprocessing on some or all of the processed data. BaTs include pan-genome analysis, computing average nucleotide identity between samples, extracting and profiling the 16S genes, and taxonomic classification using highly conserved genes. It is expected that the number of BaTs will increase to fill specific applications in the future. As a demonstration, we performed an analysis of 1,664 public Lactobacillus genomes, focusing on Lactobacillus crispatus, a species that is a common part of the human vaginal microbiome. Bactopia is an open source system that can scale from projects as small as one bacterial genome to ones including thousands of genomes and that allows for great flexibility in choosing comparison data sets and options for downstream analysis. Bactopia code can be accessed at https://www.github.com/bactopia/bactopia.IMPORTANCE It is now relatively easy to obtain a high-quality draft genome sequence of a bacterium, but bioinformatic analysis requires organization and optimization of multiple open source software tools. We present Bactopia, a pipeline for bacterial genome analysis, as an option for processing bacterial genome data. Bactopia also automates downloading of data from multiple public sources and species-specific customization. Because the pipeline is written in the Nextflow language, analyses can be scaled from individual genomes on a local computer to thousands of genomes using cloud resources. As a usage example, we processed 1,664 Lactobacillus genomes from public sources and used comparative analysis workflows (Bactopia Tools) to identify and analyze members of the L. crispatus species.},
	number = {4},
	urldate = {2025-11-01},
	journal = {mSystems},
	author = {Petit, Robert A. and Read, Timothy D.},
	month = aug,
	year = {2020},
	note = {Publisher: American Society for Microbiology},
	pages = {10.1128/msystems.00190--20},
}

@article{terron-camero_comparison_2022,
	title = {Comparison of {Metagenomics} and {Metatranscriptomics} {Tools}: {A} {Guide} to {Making} the {Right} {Choice}},
	volume = {13},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2073-4425},
	shorttitle = {Comparison of {Metagenomics} and {Metatranscriptomics} {Tools}},
	url = {https://www.mdpi.com/2073-4425/13/12/2280},
	doi = {10.3390/genes13122280},
	abstract = {The study of microorganisms is a field of great interest due to their environmental (e.g., soil contamination) and biomedical (e.g., parasitic diseases, autism) importance. The advent of revolutionary next-generation sequencing techniques, and their application to the hypervariable regions of the 16S, 18S or 23S ribosomal subunits, have allowed the research of a large variety of organisms more in-depth, including bacteria, archaea, eukaryotes and fungi. Additionally, together with the development of analysis software, the creation of specific databases (e.g., SILVA or RDP) has boosted the enormous growth of these studies. As the cost of sequencing per sample has continuously decreased, new protocols have also emerged, such as shotgun sequencing, which allows the profiling of all taxonomic domains in a sample. The sequencing of hypervariable regions and shotgun sequencing are technologies that enable the taxonomic classification of microorganisms from the DNA present in microbial communities. However, they are not capable of measuring what is actively expressed. Conversely, we advocate that metatranscriptomics is a “new” technology that makes the identification of the mRNAs of a microbial community possible, quantifying gene expression levels and active biological pathways. Furthermore, it can be also used to characterise symbiotic interactions between the host and its microbiome. In this manuscript, we examine the three technologies above, and discuss the implementation of different software and databases, which greatly impact the obtaining of reliable results. Finally, we have developed two easy-to-use pipelines leveraging Nextflow technology. These aim to provide everything required for an average user to perform a metagenomic analysis of marker genes with QIMME2 and a metatranscriptomic study using Kraken2/Bracken.},
	language = {en},
	number = {12},
	urldate = {2025-11-01},
	journal = {Genes},
	author = {Terrón-Camero, Laura C. and Gordillo-González, Fernando and Salas-Espejo, Eduardo and Andrés-León, Eduardo},
	month = dec,
	year = {2022},
	note = {Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {metagenomics, pipeline, Nextflow, metatranscriptomics, Bracken, Kraken2, 16S, QIIME2, shotgun sequencing},
	pages = {2280},
}

@article{okie_genomic_2020,
	title = {Genomic adaptations in information processing underpin trophic strategy in a whole-ecosystem nutrient enrichment experiment},
	volume = {9},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.49816},
	doi = {10.7554/eLife.49816},
	abstract = {Several universal genomic traits affect trade-offs in the capacity, cost, and efficiency of the biochemical information processing that underpins metabolism and reproduction. We analyzed the role of these traits in mediating the responses of a planktonic microbial community to nutrient enrichment in an oligotrophic, phosphorus-deficient pond in Cuatro Ciénegas, Mexico. This is one of the first whole-ecosystem experiments to involve replicated metagenomic assessment. Mean bacterial genome size, GC content, total number of tRNA genes, total number of rRNA genes, and codon usage bias in ribosomal protein sequences were all higher in the fertilized treatment, as predicted on the basis of the assumption that oligotrophy favors lower information-processing costs whereas copiotrophy favors higher processing rates. Contrasting changes in trait variances also suggested differences between traits in mediating assembly under copiotrophic versus oligotrophic conditions. Trade-offs in information-processing traits are apparently sufficiently pronounced to play a role in community assembly because the major components of metabolism—information, energy, and nutrient requirements—are fine-tuned to an organism’s growth and trophic strategy.},
	urldate = {2025-12-03},
	journal = {eLife},
	author = {Okie, Jordan G and Poret-Peterson, Amisha T and Lee, Zarraz MP and Richter, Alexander and Alcaraz, Luis D and Eguiarte, Luis E and Siefert, Janet L and Souza, Valeria and Dupont, Chris L and Elser, James J},
	editor = {Donoso, David and Weigel, Detlef},
	month = jan,
	year = {2020},
	note = {Publisher: eLife Sciences Publications, Ltd},
	keywords = {metagenomics, codon usage bias, GC content, genome size, phosphorous fertilization, rRNA operon copy number},
	pages = {e49816},
}

@article{kruchten_curricular_2020,
	title = {A {Curricular} {Bioinformatics} {Approach} to {Teaching} {Undergraduates} to {Analyze} {Metagenomic} {Datasets} {Using} {R}},
	volume = {11},
	issn = {1664-302X},
	url = {https://www.frontiersin.org/journals/microbiology/articles/10.3389/fmicb.2020.578600/full},
	doi = {10.3389/fmicb.2020.578600},
	abstract = {Biologists with bioinformatic skills will be better prepared for the job market, but relatively few biology programs require bioinformatics courses. Inclusion in the curriculum may be hindered by several barriers, including lack of faculty expertise, student resistance to computational work, and few examples in the pedagogical literature. An eight-week wet-lab and in silico research experience for undergraduates was implemented. Students performed DNA purification and metagenomics analysis to compare the diversity and abundance of microbes in two samples. Students sampled snow from sites in northern Minnesota and purified genomic DNA from the microbes, followed by metagenomic analysis. Students used an existing metagenomic dataset to practice analysis skills, including comparing the use of Excel versus R for analysis and visualization of a large dataset. Upon receipt of the snow data, students applied their recently acquired skills to their new dataset and reported their results via a poster. Several outcomes were achieved as a result of this module. First, YouTube videos demonstrating hands-on metagenomics and R techniques were used as professional development for faculty, leading to broadened research capabilities and comfort with bioinformatics. Second, students were introduced to computational skills in a manner that was intentional, with time for both introduction and reinforcement of skills. Finally, the module was effectively included in a biology curriculum because it could function as either a stand-alone course or a module within another course such as microbiology. This module, developed with Course-based Undergraduate Research Experience guidelines in mind, introduces students and faculty to bioinformatics in biology research.},
	language = {English},
	urldate = {2025-12-03},
	journal = {Frontiers in Microbiology},
	author = {Kruchten, Anne E.},
	month = sep,
	year = {2020},
	note = {Publisher: Frontiers},
	keywords = {Metagenomics, big data, bioinformatics, Biology, Curriculum, r, undergraduate},
}

@article{langer_empowering_2025,
	title = {Empowering bioinformatics communities with {Nextflow} and nf-core},
	volume = {26},
	issn = {1474-760X},
	url = {https://doi.org/10.1186/s13059-025-03673-9},
	doi = {10.1186/s13059-025-03673-9},
	abstract = {Standardized analysis pipelines contribute to making data bioinformatics research compliant with the paradigm of Findability, Accessibility, Interoperability, and Reusability (FAIR), and facilitate collaboration. Nextflow and Snakemake, two popular command-line solutions, are increasingly adopted by users, complementing GUI-based platforms such as Galaxy. We report recent developments of the nf-core framework with the new Nextflow Domain-Specific Language (DSL2). An extensive library of modules and subworkflows enables research communities to adopt common standards progressively, as resources and needs allow. We present an overview of some of the research communities built around nf-core and showcase its adoption by six EuroFAANG farmed animal research consortia.},
	language = {en},
	number = {1},
	urldate = {2025-12-03},
	journal = {Genome Biology},
	author = {Langer, Björn E. and Amaral, Andreia and Baudement, Marie-Odile and Bonath, Franziska and Charles, Mathieu and Chitneedi, Praveen Krishna and Clark, Emily L. and Di Tommaso, Paolo and Djebali, Sarah and Ewels, Philip A. and Eynard, Sonia and Fellows Yates, James A. and Fischer, Daniel and Floden, Evan W. and Foissac, Sylvain and Gabernet, Gisela and Garcia, Maxime U. and Gillard, Gareth and Gundappa, Manu Kumar and Guyomar, Cervin and Hakkaart, Christopher and Hanssen, Friederike and Harrison, Peter W. and Hörtenhuber, Matthias and Kurylo, Cyril and Kühn, Christa and Lagarrigue, Sandrine and Lallias, Delphine and Macqueen, Daniel J. and Miller, Edmund and Mir-Pedrol, Júlia and Moreira, Gabriel Costa Monteiro and Nahnsen, Sven and Patel, Harshil and Peltzer, Alexander and Pitel, Frederique and Ramayo-Caldas, Yuliaxis and Ribeiro-Dantas, Marcel da Câmara and Rocha, Dominique and Salavati, Mazdak and Sokolov, Alexey and Espinosa-Carrasco, Jose and Notredame, Cedric and community, the nf-core},
	month = jul,
	year = {2025},
	pages = {228},
}

@article{zirion-martinez_data_2024,
	title = {A {Data} {Carpentry}- {Style} {Metagenomics} {Workshop}},
	volume = {7},
	issn = {2577-3569},
	url = {https://jose.theoj.org/papers/10.21105/jose.00209},
	doi = {10.21105/jose.00209},
	abstract = {Zirión-Martínez et al., (2024). A Data Carpentry- Style Metagenomics Workshop. Journal of Open Source Education, 7(72), 209, https://doi.org/10.21105/jose.00209},
	language = {en},
	number = {72},
	urldate = {2025-11-03},
	journal = {Journal of Open Source Education},
	author = {Zirión-Martínez, Claudia and Garfias-Gallegos, Diego and Arellano-Fernandez, Tania Vanessa and Espinosa-Jaime, Aarón and Bustos-Díaz, Edder D. and Lovaco-Flores, José Abel and Tejero-Gómez, Luis Gerardo and Avelar-Rivas, J. Abraham and Sélem-Mojica, Nelly},
	month = feb,
	year = {2024},
	pages = {209},
}

@article{barker_introducing_2022,
	title = {Introducing the {FAIR} {Principles} for research software},
	volume = {9},
	copyright = {2022 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-022-01710-x},
	doi = {10.1038/s41597-022-01710-x},
	abstract = {Research software is a fundamental and vital part of research, yet significant challenges to discoverability, productivity, quality, reproducibility, and sustainability exist. Improving the practice of scholarship is a common goal of the open science, open source, and FAIR (Findable, Accessible, Interoperable and Reusable) communities and research software is now being understood as a type of digital object to which FAIR should be applied. This emergence reflects a maturation of the research community to better understand the crucial role of FAIR research software in maximising research value. The FAIR for Research Software (FAIR4RS) Working Group has adapted the FAIR Guiding Principles to create the FAIR Principles for Research Software (FAIR4RS Principles). The contents and context of the FAIR4RS Principles are summarised here to provide the basis for discussion of their adoption. Examples of implementation by organisations are provided to share information on how to maximise the value of research outputs, and to encourage others to amplify the importance and impact of this work.},
	language = {en},
	number = {1},
	urldate = {2025-12-16},
	journal = {Scientific Data},
	author = {Barker, Michelle and Chue Hong, Neil P. and Katz, Daniel S. and Lamprecht, Anna-Lena and Martinez-Ortiz, Carlos and Psomopoulos, Fotis and Harrow, Jennifer and Castro, Leyla Jael and Gruenpeter, Morane and Martinez, Paula Andrea and Honeyman, Tom},
	month = oct,
	year = {2022},
	note = {Publisher: Nature Publishing Group},
	keywords = {Policy, Research management},
	pages = {622},
}

@article{noble_quick_2009,
	title = {A {Quick} {Guide} to {Organizing} {Computational} {Biology} {Projects}},
	volume = {5},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000424},
	doi = {10.1371/journal.pcbi.1000424},
	language = {en},
	number = {7},
	urldate = {2025-12-16},
	journal = {PLOS Computational Biology},
	author = {Noble, William Stafford},
	month = jul,
	year = {2009},
	note = {Publisher: Public Library of Science},
	keywords = {Bioinformatics, Biologists, Careers in research, Computational biology, Computer software, Human learning, Software engineering, Source code},
	pages = {e1000424},
}

@article{noble_ten_2023,
	title = {Ten simple rules for defining a computational biology project},
	volume = {19},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1010786},
	doi = {10.1371/journal.pcbi.1010786},
	language = {en},
	number = {1},
	urldate = {2025-12-16},
	journal = {PLOS Computational Biology},
	author = {Noble, William Stafford},
	month = jan,
	year = {2023},
	note = {Publisher: Public Library of Science},
	keywords = {Computational biology, Control systems, Forecasting, Simulation and modeling, Software tools, Textbooks, Trainees, Verbal communication},
	pages = {e1010786},
}

@article{ewels_nf-core_2020,
	title = {The nf-core framework for community-curated bioinformatics pipelines},
	volume = {38},
	issn = {1546-1696},
	url = {https://www.nature.com/articles/s41587-020-0439-x},
	doi = {10.1038/s41587-020-0439-x},
	number = {3},
	journal = {Nature Biotechnology},
	author = {Ewels, Philip A. and Peltzer, Alexander and Fillinger, Sven and Patel, Harshil and Alneberg, Johannes and Wilm, Andreas and Garcia, Maxime Ulysse and Tommaso, Paolo Di and Nahnsen, Sven},
	month = feb,
	year = {2020},
	pmid = {32055031},
	note = {ISBN: 2018M3A9H3020459
Publisher: Nature Publishing Group},
	keywords = {Computational biology and bioinformatics, Scientific community},
	pages = {276--278},
}

@article{langmead_fast_2012,
	title = {Fast gapped-read alignment with {Bowtie} 2},
	volume = {9},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/nmeth.1923},
	doi = {10.1038/nmeth.1923},
	abstract = {The Bowtie 2 software achieves fast, sensitive, accurate and memory-efficient gapped alignment of sequencing reads using the full-text minute index and hardware-accelerated dynamic programming algorithms. As the rate of sequencing increases, greater throughput is demanded from read aligners. The full-text minute index is often used to make alignment very fast and memory-efficient, but the approach is ill-suited to finding longer, gapped alignments. Bowtie 2 combines the strengths of the full-text minute index with the flexibility and speed of hardware-accelerated dynamic programming algorithms to achieve a combination of high speed, sensitivity and accuracy.},
	number = {4},
	journal = {Nature Methods},
	author = {Langmead, Ben and Salzberg, Steven L.},
	month = mar,
	year = {2012},
	pmid = {22388286},
	note = {Publisher: Nature Publishing Group},
	keywords = {Bioinformatics, Genomics, Sequencing},
	pages = {357--359},
}

@article{lu_metagenome_2022,
	title = {Metagenome analysis using the {Kraken} software suite},
	volume = {17},
	issn = {1750-2799},
	url = {https://www.nature.com/articles/s41596-022-00738-y},
	doi = {10.1038/s41596-022-00738-y},
	abstract = {Metagenomic experiments expose the wide range of microscopic organisms in any microbial environment through high-throughput DNA sequencing. The computational analysis of the sequencing data is critical for the accurate and complete characterization of the microbial community. To facilitate efficient and reproducible metagenomic analysis, we introduce a step-by-step protocol for the Kraken suite, an end-to-end pipeline for the classification, quantification and visualization of metagenomic datasets. Our protocol describes the execution of the Kraken programs, via a sequence of easy-to-use scripts, in two scenarios: (1) quantification of the species in a given metagenomics sample; and (2) detection of a pathogenic agent from a clinical sample taken from a human patient. The protocol, which is executed within 1–2 h, is targeted to biologists and clinicians working in microbiome or metagenomics analysis who are familiar with the Unix command-line environment. The authors provide a guide to using the Kraken suite for metagenomics analysis, including classification, quantification and visualization, illustrated by quantification of species in the microbiome and identification of pathogens in a clinical sample.},
	number = {12},
	journal = {Nature Protocols},
	author = {Lu, Jennifer and Rincon, Natalia and Wood, Derrick E. and Breitwieser, Florian P. and Pockrandt, Christopher and Langmead, Ben and Salzberg, Steven L. and Steinegger, Martin},
	month = sep,
	year = {2022},
	pmid = {36171387},
	note = {Publisher: Nature Publishing Group},
	keywords = {Bioinformatics, Metagenomics, Software},
	pages = {2815--2839},
}

@article{wratten_reproducible_2021,
	title = {Reproducible, scalable, and shareable analysis pipelines with bioinformatics workflow managers},
	volume = {18},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/s41592-021-01254-9},
	doi = {10.1038/s41592-021-01254-9},
	abstract = {The rapid growth of high-throughput technologies has transformed biomedical research. With the increasing amount and complexity of data, scalability and reproducibility have become essential not just for experiments, but also for computational analysis. However, transforming data into information involves running a large number of tools, optimizing parameters, and integrating dynamically changing reference data. Workflow managers were developed in response to such challenges. They simplify pipeline development, optimize resource usage, handle software installation and versions, and run on different compute platforms, enabling workflow portability and sharing. In this Perspective, we highlight key features of workflow managers, compare commonly used approaches for bioinformatics workflows, and provide a guide for computational and noncomputational users. We outline community-curated pipeline initiatives that enable novice and experienced users to perform complex, best-practice analyses without having to manually assemble workflows. In sum, we illustrate how workflow managers contribute to making computational analysis in biomedical research shareable, scalable, and reproducible. This Perspective highlights workflow managers, which are useful for developing and managing complex bioinformatics pipelines.},
	number = {10},
	journal = {Nature Methods},
	author = {Wratten, Laura and Wilm, Andreas and Göke, Jonathan},
	month = sep,
	year = {2021},
	pmid = {34556866},
	note = {Publisher: Nature Publishing Group},
	keywords = {Computational platforms and environments, Programming language, Software},
	pages = {1161--1168},
}

@article{mcmurdie_phyloseq_2013,
	title = {phyloseq: {An} {R} {Package} for {Reproducible} {Interactive} {Analysis} and {Graphics} of {Microbiome} {Census} {Data}},
	volume = {8},
	issn = {1932-6203},
	shorttitle = {phyloseq},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0061217},
	doi = {10.1371/journal.pone.0061217},
	abstract = {Background The analysis of microbial communities through DNA sequencing brings many challenges: the integration of different types of data with methods from ecology, genetics, phylogenetics, multivariate statistics, visualization and testing. With the increased breadth of experimental designs now being pursued, project-specific statistical analyses are often needed, and these analyses are often difficult (or impossible) for peer researchers to independently reproduce. The vast majority of the requisite tools for performing these analyses reproducibly are already implemented in R and its extensions (packages), but with limited support for high throughput microbiome census data. Results Here we describe a software project, phyloseq, dedicated to the object-oriented representation and analysis of microbiome census data in R. It supports importing data from a variety of common formats, as well as many analysis techniques. These include calibration, filtering, subsetting, agglomeration, multi-table comparisons, diversity analysis, parallelized Fast UniFrac, ordination methods, and production of publication-quality graphics; all in a manner that is easy to document, share, and modify. We show how to apply functions from other R packages to phyloseq-represented data, illustrating the availability of a large number of open source analysis techniques. We discuss the use of phyloseq with tools for reproducible research, a practice common in other fields but still rare in the analysis of highly parallel microbiome census data. We have made available all of the materials necessary to completely reproduce the analysis and figures included in this article, an example of best practices for reproducible research. Conclusions The phyloseq project for R is a new open-source software package, freely available on the web from both GitHub and Bioconductor.},
	language = {en},
	number = {4},
	urldate = {2025-01-21},
	journal = {PLOS ONE},
	author = {McMurdie, Paul J. and Holmes, Susan},
	month = apr,
	year = {2013},
	note = {Publisher: Public Library of Science},
	keywords = {Census, Microbial ecology, Microbiome, Phylogenetic analysis, Phylogenetics, Preprocessing, Reproducibility, Shotgun sequencing},
	pages = {e61217},
	file = {Full Text PDF:C\:\\Users\\USER\\Zotero\\storage\\YBRJXQXN\\McMurdie and Holmes - 2013 - phyloseq An R Package for Reproducible Interactive Analysis and Graphics of Microbiome Census Data.pdf:application/pdf},
}

@article{mcdonald_biological_2012,
	title = {The {Biological} {Observation} {Matrix} ({BIOM}) format or: how {I} learned to stop worrying and love the ome-ome},
	volume = {1},
	issn = {2047-217X},
	shorttitle = {The {Biological} {Observation} {Matrix} ({BIOM}) format or},
	url = {https://doi.org/10.1186/2047-217X-1-7},
	doi = {10.1186/2047-217X-1-7},
	abstract = {We present the Biological Observation Matrix (BIOM, pronounced “biome”) format: a JSON-based file format for representing arbitrary observation by sample contingency tables with associated sample and observation metadata. As the number of categories of comparative omics data types (collectively, the “ome-ome”) grows rapidly, a general format to represent and archive this data will facilitate the interoperability of existing bioinformatics tools and future meta-analyses.The BIOM file format is supported by an independent open-source software project (the biom-format project), which initially contains Python objects that support the use and manipulation of BIOM data in Python programs, and is intended to be an open development effort where developers can submit implementations of these objects in other programming languages.The BIOM file format and the biom-format project are steps toward reducing the “bioinformatics bottleneck” that is currently being experienced in diverse areas of biological sciences, and will help us move toward the next phase of comparative omics where basic science is translated into clinical and environmental applications. The BIOM file format is currently recognized as an Earth Microbiome Project Standard, and as a Candidate Standard by the Genomic Standards Consortium.},
	number = {1},
	urldate = {2025-01-21},
	journal = {GigaScience},
	author = {McDonald, Daniel and Clemente, Jose C and Kuczynski, Justin and Rideout, Jai Ram and Stombaugh, Jesse and Wendel, Doug and Wilke, Andreas and Huse, Susan and Hufnagle, John and Meyer, Folker and Knight, Rob and Caporaso, J Gregory},
	month = dec,
	year = {2012},
	pages = {2047--217X--1--7},
	file = {Full Text PDF:C\:\\Users\\USER\\Zotero\\storage\\E6G2XRJJ\\McDonald et al. - 2012 - The Biological Observation Matrix (BIOM) format or how I learned to stop worrying and love the ome-.pdf:application/pdf;Full Text PDF:C\:\\Users\\USER\\Zotero\\storage\\5537MFLN\\McDonald et al. - 2012 - The Biological Observation Matrix (BIOM) format or how I learned to stop worrying and love the ome-.pdf:application/pdf;Snapshot:C\:\\Users\\USER\\Zotero\\storage\\8HDA69UI\\2656152.html:text/html},
}

@article{ondov_interactive_2011,
	title = {Interactive metagenomic visualization in a {Web} browser},
	volume = {12},
	copyright = {2011 Ondov et al; licensee BioMed Central Ltd.},
	issn = {1471-2105},
	url = {https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-12-385},
	doi = {10.1186/1471-2105-12-385},
	abstract = {A critical output of metagenomic studies is the estimation of abundances of taxonomical or functional groups. The inherent uncertainty in assignments to these groups makes it important to consider both their hierarchical contexts and their prediction confidence. The current tools for visualizing metagenomic data, however, omit or distort quantitative hierarchical relationships and lack the facility for displaying secondary variables. Here we present Krona, a new visualization tool that allows intuitive exploration of relative abundances and confidences within the complex hierarchies of metagenomic classifications. Krona combines a variant of radial, space-filling displays with parametric coloring and interactive polar-coordinate zooming. The HTML5 and JavaScript implementation enables fully interactive charts that can be explored with any modern Web browser, without the need for installed software or plug-ins. This Web-based architecture also allows each chart to be an independent document, making them easy to share via e-mail or post to a standard Web server. To illustrate Krona's utility, we describe its application to various metagenomic data sets and its compatibility with popular metagenomic analysis tools. Krona is both a powerful metagenomic visualization tool and a demonstration of the potential of HTML5 for highly accessible bioinformatic visualizations. Its rich and interactive displays facilitate more informed interpretations of metagenomic analyses, while its implementation as a browser-based application makes it extremely portable and easily adopted into existing analysis packages. Both the Krona rendering code and conversion tools are freely available under a BSD open-source license, and available from: http://krona.sourceforge.net .},
	language = {en},
	number = {1},
	urldate = {2025-01-21},
	journal = {BMC Bioinformatics},
	author = {Ondov, Brian D. and Bergman, Nicholas H. and Phillippy, Adam M.},
	month = dec,
	year = {2011},
	note = {Number: 1
Publisher: BioMed Central},
	pages = {1--10},
	file = {Full Text:C\:\\Users\\USER\\Zotero\\storage\\ADJ3THND\\Ondov et al. - 2011 - Interactive metagenomic visualization in a Web browser.pdf:application/pdf},
}

@article{kadri_containers_2022,
	title = {Containers in {Bioinformatics}: {Applications}, {Practical} {Considerations}, and {Best} {Practices} in {Molecular} {Pathology}},
	volume = {24},
	issn = {1525-1578},
	shorttitle = {Containers in {Bioinformatics}},
	url = {https://www.sciencedirect.com/science/article/pii/S1525157822000381},
	doi = {10.1016/j.jmoldx.2022.01.006},
	abstract = {Systematic implementation of bioinformatics resources for next generation sequencing (NGS)-based clinical testing is an arduous undertaking. One of the key challenges involves developing an ecosystem of information technology infrastructure for enabling scalable and reproducible bioinformatics services that is resilient and secure for handling genetic and protected health information, often embedded in an existing non–bioinformatics-oriented infrastructure. Container technology provides an ideal and infrastructure-agnostic solution for molecular laboratories developing and using bioinformatics pipelines, whether on-premise or using the cloud. A container is a technology that provides a consistent computational environment and enables reproducibility, scalability, and security when developing NGS bioinformatics analysis pipelines. Containers can increase the bioinformatics team's productivity by automating and simplifying the maintenance of complex bioinformatics resources, as well as facilitate validation, version control, and documentation necessary for clinical laboratory regulatory compliance. Although there is increasing popularity in adopting containers for developing NGS bioinformatics pipelines, there is wide variability and inconsistency in the usage of containers that may result in suboptimal performance and potentially compromise the security and privacy of protected health information. In this article, the authors highlight the current state and provide best or recommended practices for building, using containers in NGS bioinformatics solutions in a clinical setting with focus on scalability, optimization, maintainability, and data security.},
	number = {5},
	urldate = {2025-05-26},
	journal = {The Journal of Molecular Diagnostics},
	author = {Kadri, Sabah and Sboner, Andrea and Sigaras, Alexandros and Roy, Somak},
	month = may,
	year = {2022},
	pages = {442--454},
	file = {ScienceDirect Snapshot:C\:\\Users\\USER\\Zotero\\storage\\JFMQ765U\\S1525157822000381.html:text/html},
}

@article{roach_ten_2022,
	title = {Ten simple rules and a template for creating workflows-as-applications},
	volume = {18},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1010705},
	doi = {10.1371/journal.pcbi.1010705},
	language = {en},
	number = {12},
	urldate = {2025-05-26},
	journal = {PLOS Computational Biology},
	author = {Roach, Michael J. and Pierce-Ward, N. Tessa and Suchecki, Radoslaw and Mallawaarachchi, Vijini and Papudeshi, Bhavya and Handley, Scott A. and Brown, C. Titus and Watson-Haigh, Nathan S. and Edwards, Robert A.},
	month = dec,
	year = {2022},
	note = {Publisher: Public Library of Science},
	keywords = {Bioinformatics, Computer software, Language, Operating systems, Preprocessing, Pythons, Software tools, User interfaces},
	pages = {e1010705},
	file = {Full Text PDF:C\:\\Users\\USER\\Zotero\\storage\\3UHUXUD2\\Roach et al. - 2022 - Ten simple rules and a template for creating workflows-as-applications.pdf:application/pdf},
}

@misc{wf-metagenomics,
  title = {wf-metagenomics},
  author = {EPI2ME},
  year = {2021},
  url = {https://github.com/epi2me-labs/wf-metagenomics},
  note = {Accessed 2025-12-17}
}

@misc{kraken-nf,
  title = {kraken-nf},
  author = {Borry, Maxime},
  year = {2019},
  url = {https://github.com/maxibor/kraken-nf},
  note = {Accessed 2025-12-17}
}

@misc{nxf-kraken2,
  title = {nxf-kraken2},
  author = {Angelov, Angel},
  year = {2020},
  url = {https://github.com/angelovangel/nxf-kraken2},
  note = {Accessed 2025-12-17}
}

@misc{nextflow-example,
  title = {nextflow-example},
  author = {Telatin, Andrea},
  year = {2022},
  url = {https://github.com/telatin/nextflow-example},
  note = {Accessed 2025-12-17}
}

@article{wood_improved_2019,
	title = {Improved metagenomic analysis with {Kraken} 2},
	volume = {20},
	copyright = {2019 The Author(s).},
	issn = {1474-760X},
	url = {https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1891-0},
	doi = {10.1186/s13059-019-1891-0},
	abstract = {Although Kraken’s k-mer-based approach provides a fast taxonomic classification of metagenomic sequence data, its large memory requirements can be limiting for some applications. Kraken 2 improves upon Kraken 1 by reducing memory usage by 85\%, allowing greater amounts of reference genomic data to be used, while maintaining high accuracy and increasing speed fivefold. Kraken 2 also introduces a translated search mode, providing increased sensitivity in viral metagenomics analysis.},
	language = {en},
	number = {1},
	urldate = {2025-01-21},
	journal = {Genome Biology},
	author = {Wood, Derrick E. and Lu, Jennifer and Langmead, Ben},
	month = dec,
	year = {2019},
	note = {Number: 1
Publisher: BioMed Central},
	pages = {1--13},
	file = {Full Text:/Users/yepesgar/Zotero/storage/TNYLJXBC/Wood et al. - 2019 - Improved metagenomic analysis with Kraken 2.pdf:application/pdf},
}

@article{lu_bracken_2017,
	title = {Bracken: {Estimating} species abundance in metagenomics data},
	volume = {2017},
	issn = {23765992},
	url = {https://peerj.com/articles/cs-104},
	doi = {10.7717/PEERJ-CS.104/SUPP-5},
	abstract = {Metagenomic experiments attempt to characterize microbial communities using high-throughput DNA sequencing. Identification of the microorganisms in a sample provides information about the genetic profile, population structure, and role of microorganisms within an environment. Until recently, most metagenomics studies focused on high-level characterization at the level of phyla, or alternatively sequenced the 16S ribosomalRNAgene that is present in bacterial species. As the cost of sequencing has fallen, though, metagenomics experiments have increasingly used unbiased shotgun sequencing to capture all the organisms in a sample. This approach requires a method for estimating abundance directly from the raw read data. Here we describe a fast, accurate new method that computes the abundance at the species level using the reads collected in a metagenomics experiment. Bracken (Bayesian Reestimation of Abundance after Classification with KrakEN) uses the taxonomic assignments made by Kraken, a very fast read-level classifier, along with information about the genomes themselves to estimate abundance at the species level, the genus level, or above. We demonstrate that Bracken can produce accurate species- and genus-level abundance estimates even when a sample contains multiple near-identical species.},
	number = {1},
	journal = {PeerJ Computer Science},
	author = {Lu, Jennifer and Breitwieser, Florian P. and Thielen, Peter and Salzberg, Steven L.},
	month = jan,
	year = {2017},
	note = {Publisher: PeerJ Inc.},
	keywords = {Bayesian estimation, Metagenomics, Microbiome, Species abundance},
	pages = {e104},
}